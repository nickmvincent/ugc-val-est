<p><strong>Test 1</strong>: Connect and Disconnect clients like mad, to see how well you handle the init and end of sessions, and just how much your server will survive under spikes, also while doing this measure how many clients fail to connect. That is very important</p>

<p><strong>Test 2</strong>: Connect clients and keep them logged on for say a week, doing random actions <a href="http://en.wikipedia.org/wiki/Fuzz_testing" rel="noreferrer">(FuzzTest)</a>. Time the round-trip of each action. Also keep record of the order of actions, because this way your "clients" will find loopholes in your usecases (very important, and VERY hard to test rationally).</p>

<p><strong>Test 3 &amp; 4</strong>: Determine major use cases for your system, and write up scripts that do these tasks. Then run several clients doing same task(test 3), and also several clients doing different tasks(test 4).</p>

<p><strong>Series:</strong>
Now the other dimension you need here is amount of clients.
A nice series would be:
5,10,50,100,500,1000,5000,10000,...</p>

<p>This way you can get data for each series of tests with different work loads.</p>

<p>Also congrats on SWIGing your clients api to Python! That is a great way to get things ready. </p>

<p>Note: <a href="http://www.ibm.com/developerworks/java/library/j-fuzztest.html" rel="noreferrer">IBM has a sample of fuzz testing on Java</a>, which is unrealted to your case, but will help you design a good fuzztest for your system</p>
